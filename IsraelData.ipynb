{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IsraelData.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fE1EJt4MXREz","executionInfo":{"status":"ok","timestamp":1630789090518,"user_tz":-180,"elapsed":7990,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}},"outputId":"76c5d799-bdf0-46d9-e7d7-198c638160c9"},"source":["#### IMPORTS  ####\n","from pathlib import Path\n","from typing import Tuple, List\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import tqdm\n","import random\n","import datetime\n","import pathlib\n","import pytz\n","import glob\n","import re\n","from google.colab import drive\n","from torch.autograd import Variable\n","import seaborn as sns\n","import os\n","import shutil\n","import copy\n","import matplotlib.dates as mdates\n","from datetime import datetime, timedelta\n","import scipy.io\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"odHL79Gnm31i"},"source":["pd.DataFrame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDuParlMjZYO","executionInfo":{"status":"ok","timestamp":1630789098249,"user_tz":-180,"elapsed":270,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}}},"source":["HEIGHT = 30\n","WIDTH = 34"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAvSmi63pk_l","executionInfo":{"status":"ok","timestamp":1630792191200,"user_tz":-180,"elapsed":272,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}}},"source":["def matlab_to_datetime(mtime):\n","  # from matlab datenum to python datetime and round to the nearest minute\n","  ptime = [datetime.fromordinal(int(mtime[i])) + timedelta(days=mtime[i]%1) - timedelta(days = 366) for i in range(0,len(mtime))]\n","  ptimernd = [datetime(ptime[i].year, ptime[i].month, ptime[i].day, ptime[i].hour, ptime[i].minute)+ timedelta(minutes=(ptime[i].second>30)) for i in range(0,len(mtime))]\n","  ptime = np.asarray(ptimernd)\n","  return ptime\n","\n","def read_matlab_event_file(file_name):\n","  # read .mat file of event struct\n","  data = scipy.io.loadmat(file_name=file_name, squeeze_me=True, struct_as_record=True)\n","  data = data['event_struc']\n","  event_num = data.shape[0]\n","  print(['Number of events: ',event_num])\n","  ls = []\n","  for en in range(0,event_num):\n","    peak_time = matlab_to_datetime([data[en][0]])[0]\n","    event_start = matlab_to_datetime([data[en][1]])[0]\n","    event_end = matlab_to_datetime([data[en][2]])[0]\n","    duration_h = data[en][3]\n","    flow_times = matlab_to_datetime(data[en][4])\n","    flow_vals = data[en][5]\n","    radar_rain = data[en][6]\n","    radar_times = matlab_to_datetime(data[en][7])\n","    flow_vals_interp = np.interp(data[en][7], data[en][4], data[en][5]) # TODO: 1) flow time goes beyond radar time and should be added. 2) peak is truncated due to the interpolation\n","    ls.append([peak_time,event_start,event_end,duration_h,flow_times, flow_vals, radar_rain, radar_times, flow_vals_interp])\n","\n","  pd_events = pd.DataFrame(data=ls, columns = ['peak_time','start','end','duration_h','flow_times', 'flow_vals', 'radar_rain', 'radar_times', 'flow_vals_interp'])\n","\n","  return pd_events\n","\n","def reshape_data(x: np.ndarray, y: np.ndarray, seq_length: int) -> Tuple[np.ndarray, np.ndarray]:\n","  \"\"\"\n","  Reshape matrix data into sample shape for LSTM training.\n","  :param x: Matrix containing input features column wise and time steps row wise\n","  :param y: Matrix containing the output feature.\n","  :param seq_length: Length of look back days for one day of prediction \n","  :return: Two np.ndarrays, the first of shape (samples, length of sequence,\n","    number of features), containing the input data for the LSTM. The second\n","    of shape (samples, 1) containing the expected output for each input\n","    sample.\n","  \"\"\"\n","  num_samples, num_features = x.shape\n","  x_new = np.zeros((num_samples - seq_length + 1, seq_length, num_features))\n","  y_new = np.zeros((num_samples - seq_length + 1, 1))\n","  for i in range(0, x_new.shape[0]):\n","    x_new[i, :, :num_features] = x[i:i + seq_length, :]\n","    y_new[i, :] = y[i + seq_length - 1, 0]\n","  return x_new, y_new"],"execution_count":137,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZydqLE_nOWWl","executionInfo":{"status":"ok","timestamp":1630791756924,"user_tz":-180,"elapsed":623,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}},"outputId":"7ee94fca-60b9-488b-900a-553446ceec4b"},"source":["PATH_ROOT = \"drive/MyDrive/Efrat/\"# Change only here the path\n","file_name=PATH_ROOT+'/Data/Israel/event_struc.mat'\n","pd_events = read_matlab_event_file(file_name)"],"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["['Number of events: ', 22]\n"]}]},{"cell_type":"code","metadata":{"id":"GtPunjfK2hsd","executionInfo":{"status":"ok","timestamp":1630792197196,"user_tz":-180,"elapsed":285,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}}},"source":["class Israel(Dataset):\n","  \"\"\"\n","  Torch Dataset for basic use of data from the data set. \n","  This data set provides meteorological observations and discharge of a given basin from the Israel data set.\n","  \"\"\"\n","  def __init__(self, df_all_data: pd.DataFrame, event_list: List, seq_length: int, period: str=None, min_value: np.array=None, max_value: np.array=None, lead=0):\n","    \"\"\"Initialize Dataset containing the data of a single basin.\n","    :param seq_length: Length of the time window of meteorological input provided for one time step of prediction.\n","    :param period: (optional) One of ['train', 'eval']. None loads the entire time series.\n","    :param dates: (optional) List ofthe start and end date of the discharge period that is used.\n","    \"\"\"\n","    self.seq_length = seq_length\n","    self.event_list = event_list\n","    self.period = period\n","    self.min_value = min_value\n","    self.max_value = max_value\n","    self.mean_y = None\n","    self.std_y = None\n","    self.lead = lead\n","    self.num_features = None\n","    self.event_length_list = []\n","    # load data\n","    self.x , self.y= self._load_data(df_all_data)\n","    # store number of samples as class attribute\n","    self.num_samples = self.x.shape[0]\n","    # store number of features as class attribute\n","\n","  def __len__(self):\n","    return self.num_samples\n","\n","  def __getitem__(self, idx: int):\n","    return self.x[idx], self.y[idx]\n","\n","  def _load_data(self, df_all_data):\n","    \"\"\"Load input and output data from dataframe.    \"\"\"\n","    first_event = True\n","    for event_idx in self.event_list:\n","      event_size = len(df_all_data['flow_vals_interp'][event_idx])\n","      x_event, y_event = self._load_event(df_all_data['radar_rain'][event_idx], df_all_data['flow_vals_interp'][event_idx], event_size)\n","      print(f\"Event {event_idx}, x.shape = {x_event.shape}, y.shape = {y_event.shape}\")\n","      self.event_length_list.append(len(y_event))\n","      if first_event:\n","        x, y = x_event, y_event\n","        first_event = False\n","      else:\n","        x = np.concatenate([x, x_event], axis=0)\n","        y = np.concatenate([y, y_event])\n","    if self.period == 'train':\n","      self.min_value  = x.min()\n","      self.max_value = x.max()\n","    # Normalizing the rain data  \n","    x -= self.min_value\n","    x /= (self.max_value - self.min_value)\n","    \n","    if self.period == \"train\":\n","      # normalize discharge\n","      self.mean_y = y.mean()\n","      self.std_y = y.std()\n","      y = self._local_normalization(y, variable='output')\n","    print(\"Data set for {0} for Events: {1}\".format(self.period, self.event_list))\n","    print(\"Data size for LSTM should be: (num_samples, sequence_len, num_features) = {0}\".format(x.shape))    \n","    # convert arrays to torch tensors\n","    x = torch.from_numpy(x.astype(np.float32))\n","    y = torch.from_numpy(y.astype(np.float32))\n","    return x, y\n","  \n","  def _load_event(self, event_data, event_label, event_size):\n","    \n","    # Clean nan \n","    event_data[np.isnan(event_data)] = 0.0\n","    # Reshahpe data to 1D\n","    x = np.reshape(event_data, (HEIGHT*WIDTH, event_data.shape[2])).T\n","    return reshape_data(x[:(event_size - self.lead),:], np.matrix(event_label[self.lead:]).T, self.seq_length)\n","  \n","  def _local_normalization(self, feature: np.ndarray, variable: str) -> np.ndarray:\n","    \"\"\"Normalize input/output features with local mean/std.\"\"\"\n","    if variable == 'output':\n","      feature = (feature - self.mean_y) /self.std_y\n","    else:\n","      raise RuntimeError(f\"Unknown variable type {variable}\")\n","    return feature\n","  \n","  def local_rescale(self, feature: np.ndarray, variable: str) -> np.ndarray:\n","    \"\"\"Rescale output features with local mean/std.\n","      :param feature: Numpy array containing the feature(s) as matrix.\n","      param variable: Either 'inputs' or 'output' showing which feature will\n","      be normalized\n","    :return: array containing the normalized feature\n","    \"\"\"\n","    if variable == 'output':\n","      feature = feature * self.std_y + self.mean_y\n","    else:\n","      raise RuntimeError(f\"Unknown variable type {variable}\")\n","    return feature\n","\n","  def get_min(self):\n","    return self.min_value\n","\n","  def get_max(self):\n","    return self.max_value\n","\n","  def get_mean_y(self):\n","    return self.mean_y\n","\n","  def get_std_y(self):\n","    return self.std_y\n","    \n","  def get_num_features(self):\n","    return self.num_features\n","\n","\n","\n"],"execution_count":138,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c59yWvBEjDXL","executionInfo":{"status":"ok","timestamp":1630792200107,"user_tz":-180,"elapsed":1035,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}},"outputId":"28e4b086-4a66-4b81-b420-50e2b225bd7c"},"source":["ds_temp  = Israel(pd_events, event_list=[1,3,5,7,8], seq_length=36, period='train', lead=1)"],"execution_count":139,"outputs":[{"output_type":"stream","name":"stdout","text":["Event 1, x.shape = (255, 36, 1020), y.shape = (255, 1)\n","Event 3, x.shape = (255, 36, 1020), y.shape = (255, 1)\n","Event 5, x.shape = (255, 36, 1020), y.shape = (255, 1)\n","Event 7, x.shape = (118, 36, 1020), y.shape = (118, 1)\n","Event 8, x.shape = (399, 36, 1020), y.shape = (399, 1)\n","Data set for train for Events: [1, 3, 5, 7, 8]\n","Data size for LSTM should be: (num_samples, sequence_len, num_features) = (1282, 36, 1020)\n"]}]},{"cell_type":"code","metadata":{"id":"BocHxoGYjDkg","executionInfo":{"status":"ok","timestamp":1630792676101,"user_tz":-180,"elapsed":274,"user":{"displayName":"Ronen Rojas","photoUrl":"","userId":"06234689977909850809"}}},"source":["class DNN(nn.Module):\n","  def __init__(self, input_size: int, num_hidden_layers: int, num_hidden_units: int, dropout_rate: float=0.0):\n","    super(DNN, self).__init__()\n","    self.input_size = input_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.num_hidden_units = num_hidden_units\n","    self.dropout_rate = dropout_rate    \n","    self.input_layer = nn.Linear(self.input_size, self.num_hidden_units)\n","    self.hidden_layer = nn.Linear(self.num_hidden_units, self.num_hidden_units)\n","    self.output_layer = nn.Linear(self.num_hidden_units, 1)\n","    self.dropout = nn.Dropout(p=self.dropout_rate)\n","\n","  def forward(self, x):\n","    batch_size, timesteps, ts_size = x.size()\n","    x = x.view(batch_size, timesteps*ts_size)\n","    x = self.input_layer(x)\n","    for i in range(0,self.num_hidden_layers):\n","      x = self.hidden_layer(F.relu(self.hidden_layer(x)))\n","    pred = self.dropout(self.output_layer(x))\n","    return pred\n","\n","\n","class CNN(nn.Module):\n","  def __init__(self, num_channels: int, input_size: int):\n","    super(CNN, self).__init__()\n","    self.conv1 = nn.Conv2d(num_channels, 16, 3)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.conv2 = nn.Conv2d(16, 32, 3)\n","    self.fc1 = nn.Linear(2688, 120)\n","    self.fc2 = nn.Linear(120, input_size)\n","    self.dropout1 = nn.Dropout()\n","\n","  def forward(self, x):\n","    x = self.pool(F.relu(self.conv1(x)))\n","    x = self.pool(F.relu(self.conv2(x)))\n","    x = x.view(-1, 2688)\n","    x = self.dropout1(F.relu(self.fc1(x)))\n","    x = self.fc2(x)\n","    return x\n","\n","\n","class CNNLSTM(nn.Module):\n","#  def __init__(self, input_size: int , hidden_size: int, num_channels: int, dropout_rate: float=0.0, num_layers: int=1, num_attributes: int=1):\n","  def __init__(self, input_size: int , hidden_size: int, num_channels: int, dropout_rate: float=0.0, num_layers: int=1, num_attributes: int=0):\n","    \"\"\"Initialize model    \n","       :param hidden_size: Number of hidden units/LSTM cells\n","      :param dropout_rate: Dropout rate of the last fully connected layer. Default 0.0\n","    \"\"\"\n","    super(CNNLSTM, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.dropout_rate = dropout_rate    \n","    self.num_channels = num_channels\n","    self.cnn = CNN(num_channels=num_channels, input_size=(input_size - num_attributes))\n","    # create required layer\n","    self.lstm = nn.LSTM(input_size=input_size, hidden_size=self.hidden_size, num_layers=num_layers, bias=True, batch_first=True)\n","    self.dropout = nn.Dropout(p=self.dropout_rate)\n","    self.fc = nn.Linear(in_features=self.hidden_size, out_features=1)\n","        \n","  def forward(self, x: torch.Tensor) -> torch.Tensor:\n","    \"\"\"Forward pass through the Network.  \n","      param x: Tensor of shape [batch size, seq length, num features] containing the input data for the LSTM network.\n","      :return: Tensor containing the network predictions\n","    \"\"\"\n","    #print(x.size())\n","    batch_size, timesteps, _ = x.size()\n","    # cropping the \"image\" part of the input\n","    image = x[:,:, :self.num_channels*HEIGHT*W_LON]\n","    image= image.view(batch_size, timesteps, self.num_channels, HEIGHT*WIDTH)\n","    image= image.view(batch_size, timesteps, self.num_channels, HEIGHT, WIDTH)\n","    c_in = image.view(batch_size * timesteps, self.num_channels, HEIGHT, WIDTH)\n","    # CNN part\n","    c_out = self.cnn(c_in)\n","    # CNN output should in the size of input size - atrributes_size\n","    cnn_out = c_out.view(batch_size, timesteps, -1)\n","    # cropping the \"image\" part of the input \n","    a_in = x[:,:, self.num_channels*HEIGHT*WIDTH:]\n","    r_in = torch.cat((cnn_out, a_in), 2)\n","    output, (h_n, c_n) = self.lstm(r_in)\n","    # perform prediction only at the end of the input sequence\n","    pred = self.fc(self.dropout(h_n[-1,:,:]))\n","    return pred\n"],"execution_count":152,"outputs":[]}]}