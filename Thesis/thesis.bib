% 1.
@article{Mcgovern,
	author = {Mcgovern, Amy and Lagerquist, Ryan and Gagne, David and Jergensen, G. and Elmore, Kimberly and Homeyer, Cameron and Smith, Travis},
	year = {2019},
	month = {08},
	pages = {},
	title = {Making the Black Box More Transparent: Understanding the Physical Implications of Machine Learning},
	volume = {100},
	journal = {Bulletin of the American Meteorological Society},
	doi = {10.1175/BAMS-D-18-0195.1}
}

% 2. Extensive book about interpatibitly 
@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

% 3. Cite for deep learining in general for the intro
@misc{he2015deep,
	author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title={Deep Residual Learning for Image Recognition}, 
	year={2015},
	eprint={1512.03385},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

% 4. Cite for deep learining in general for the intro
@article{DBLP:journals/corr/abs-1805-01890,
	author    = {Kamran Kowsari and
	Mojtaba Heidarysafa and
	Donald E. Brown and
	Kiana Jafari Meimandi and
	Laura E. Barnes},
	title     = {{RMDL:} Random Multimodel Deep Learning for Classification},
	journal   = {CoRR},
	volume    = {abs/1805.01890},
	year      = {2018},
	url       = {http://arxiv.org/abs/1805.01890},
	eprinttype = {arXiv},
	eprint    = {1805.01890},
	timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1805-01890.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 5. Cite for deep learining in general for the intro
@article{DBLP:journals/corr/abs-1905-01392,
	author    = {Martin Wistuba and
	Ambrish Rawat and
	Tejaswini Pedapati},
	title     = {A Survey on Neural Architecture Search},
	journal   = {CoRR},
	volume    = {abs/1905.01392},
	year      = {2019},
	url       = {http://arxiv.org/abs/1905.01392},
	eprinttype = {arXiv},
	eprint    = {1905.01392},
	timestamp = {Mon, 27 May 2019 13:15:00 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-01392.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 6. Cite for deep learining in general for the intro
@article{DBLP:journals/corr/MnihKSGAWR13,
	author    = {Volodymyr Mnih and
	Koray Kavukcuoglu and
	David Silver and
	Alex Graves and
	Ioannis Antonoglou and
	Daan Wierstra and
	Martin A. Riedmiller},
	title     = {Playing Atari with Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1312.5602},
	year      = {2013},
	url       = {http://arxiv.org/abs/1312.5602},
	eprinttype = {arXiv},
	eprint    = {1312.5602},
	timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 7. Cite for deep learining in general for the intro
@article{Silver_2016,
	added-at = {2016-03-11T14:36:05.000+0100},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
	doi = {10.1038/nature16961},
	interhash = {48430c7891aaf9fe2582faa8f5d076c1},
	intrahash = {9e987f58d895c490144693139cbc90c7},
	journal = {Nature},
	keywords = {baduk go google},
	month = jan,
	number = 7587,
	pages = {484--489},
	publisher = {Nature Publishing Group},
	timestamp = {2016-03-11T14:37:40.000+0100},
	title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
	volume = 529,
	year = 2016
}

% 8. Integrated Gradient paper
@article{DBLP:journals/corr/SundararajanTY17,
	author    = {Mukund Sundararajan and
	Ankur Taly and
	Qiqi Yan},
	title     = {Axiomatic Attribution for Deep Networks},
	journal   = {CoRR},
	volume    = {abs/1703.01365},
	year      = {2017},
	url       = {http://arxiv.org/abs/1703.01365},
	eprinttype = {arXiv},
	eprint    = {1703.01365},
	timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SundararajanTY17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 9. Local attributions Vs. Global and Sensitivity-n metric
@misc{https://doi.org/10.48550/arxiv.1711.06104,
	doi = {10.48550/ARXIV.1711.06104},
	url = {https://arxiv.org/abs/1711.06104},
	author = {Ancona, Marco and Ceolini, Enea and Öztireli, Cengiz and Gross, Markus},
	keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Towards better understanding of gradient-based attribution methods for Deep Neural Networks},
	publisher = {arXiv},
	year = {2017},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 10. Deep Lift Shap
@article{DBLP:journals/corr/LundbergL17,
	author    = {Scott M. Lundberg and
	Su{-}In Lee},
	title     = {A unified approach to interpreting model predictions},
	journal   = {CoRR},
	volume    = {abs/1705.07874},
	year      = {2017},
	url       = {http://arxiv.org/abs/1705.07874},
	eprinttype = {arXiv},
	eprint    = {1705.07874},
	timestamp = {Fri, 26 Nov 2021 16:33:36 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/LundbergL17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 11.
@article{DBLP:journals/corr/ShrikumarGK17,
	author    = {Avanti Shrikumar and
	Peyton Greenside and
	Anshul Kundaje},
	title     = {Learning Important Features Through Propagating Activation Differences},
	journal   = {CoRR},
	volume    = {abs/1704.02685},
	year      = {2017},
	url       = {http://arxiv.org/abs/1704.02685},
	eprinttype = {arXiv},
	eprint    = {1704.02685},
	timestamp = {Thu, 14 Oct 2021 09:14:21 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ShrikumarGK17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 12. 
@article{DBLP:journals/corr/abs-2111-07668,
	author    = {Robin Hesse and
	Simone Schaub{-}Meyer and
	Stefan Roth},
	title     = {Fast Axiomatic Attribution for Neural Networks},
	journal   = {CoRR},
	volume    = {abs/2111.07668},
	year      = {2021},
	url       = {https://arxiv.org/abs/2111.07668},
	eprinttype = {arXiv},
	eprint    = {2111.07668},
	timestamp = {Tue, 16 Nov 2021 12:12:31 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2111-07668.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 13. 
@article{DBLP:journals/corr/abs-1802-00614,
	author    = {Quanshi Zhang and
	Song{-}Chun Zhu},
	title     = {Visual Interpretability for Deep Learning: a Survey},
	journal   = {CoRR},
	volume    = {abs/1802.00614},
	year      = {2018},
	url       = {http://arxiv.org/abs/1802.00614},
	eprinttype = {arXiv},
	eprint    = {1802.00614},
	timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1802-00614.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
 
% 14. Benchmark
@misc{https://doi.org/10.48550/arxiv.1806.10758,
	doi = {10.48550/ARXIV.1806.10758},
	url = {https://arxiv.org/abs/1806.10758},
	author = {Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
	keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {A Benchmark for Interpretability Methods in Deep Neural Networks},
	publisher = {arXiv},
	year = {2018},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 15. 
@misc{https://doi.org/10.48550/arxiv.1509.06321,
	doi = {10.48550/ARXIV.1509.06321},
	url = {https://arxiv.org/abs/1509.06321},
	author = {Samek, Wojciech and Binder, Alexander and Montavon, Grégoire and Bach, Sebastian and Müller, Klaus-Robert},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Evaluating the visualization of what a Deep Neural Network has learned},
	publisher = {arXiv},
	year = {2015},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 16. 
@article{DBLP:journals/corr/abs-2003-07631,
	author    = {Wojciech Samek and
	Grégoire Montavon and
	Sebastian Lapuschkin and
	Christopher J. Anders and
	Klaus-Robert Müller},
	title     = {Toward Interpretable Machine Learning: Transparent Deep Neural Networks
	and Beyond},
	journal   = {CoRR},
	volume    = {abs/2003.07631},
	year      = {2020},
	url       = {https://arxiv.org/abs/2003.07631},
	eprinttype = {arXiv},
	eprint    = {2003.07631},
	timestamp = {Tue, 24 Mar 2020 16:42:29 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2003-07631.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 17. referenceExplanation Selectivity
@article{DBLP:journals/corr/MontavonSM17,
	author    = {Grégoire Montavon and
	Wojciech Samek and
	Klaus-Robert Müller},
	title     = {Methods for Interpreting and Understanding Deep Neural Networks},
	journal   = {CoRR},
	volume    = {abs/1706.07979},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.07979},
	eprinttype = {arXiv},
	eprint    = {1706.07979},
	timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/MontavonSM17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 18. LRP Method 
@article{LRP,
	author = {Lapuschkin, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2015},
	month = {07},
	pages = {e0130140},
	title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
	volume = {10},
	journal = {PLoS ONE},
	doi = {10.1371/journal.pone.0130140}
}

% 19. LRP word emmbeding zero
@article{DBLP:journals/corr/ArrasHMMS16a,
	author    = {Leila Arras and
	Franziska Horn and
	Grégoire  Montavon and
	Klaus-Robert Müller and
	Wojciech Samek},
	title     = {"What is Relevant in a Text Document?": An Interpretable Machine Learning
	Approach},
	journal   = {CoRR},
	volume    = {abs/1612.07843},
	year      = {2016},
	url       = {http://arxiv.org/abs/1612.07843},
	eprinttype = {arXiv},
	eprint    = {1612.07843},
	timestamp = {Mon, 13 Aug 2018 16:47:50 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ArrasHMMS16a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 20. Debugging reference 1
@misc{https://doi.org/10.48550/arxiv.1810.03292,
	doi = {10.48550/ARXIV.1810.03292},
	url = {https://arxiv.org/abs/1810.03292},
	author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Sanity Checks for Saliency Maps},
	publisher = {arXiv},
	year = {2018},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 21. Debugging reference 2
@article{DBLP:journals/corr/abs-2011-05429,
	author    = {Julius Adebayo and
	Michael Muelly and
	Ilaria Liccardi and
	Been Kim},
	title     = {Debugging Tests for Model Explanations},
	journal   = {CoRR},
	volume    = {abs/2011.05429},
	year      = {2020},
	url       = {https://arxiv.org/abs/2011.05429},
	eprinttype = {arXiv},
	eprint    = {2011.05429},
	timestamp = {Thu, 12 Nov 2020 15:14:56 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2011-05429.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 22. Gradient Method refernece 
@article{baehrens2010explain,
	title={How to explain individual classification decisions},
	author={Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\"u}ller, Klaus-Robert},
	journal={The Journal of Machine Learning Research},
	volume={11},
	pages={1803--1831},
	year={2010},
	publisher={JMLR. org}
}

% 23. Gradient Method refernece 
@misc{https://doi.org/10.48550/arxiv.1312.6034,
	doi = {10.48550/ARXIV.1312.6034},
	url = {https://arxiv.org/abs/1312.6034},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	publisher = {arXiv},
	year = {2013},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 24. Smooth Gradient Method refernece 
@article{DBLP:journals/corr/SmilkovTKVW17,
	author    = {Daniel Smilkov and
	Nikhil Thorat and
	Been Kim and
	Fernanda B. Vi{\'{e}}gas and
	Martin Wattenberg},
	title     = {SmoothGrad: removing noise by adding noise},
	journal   = {CoRR},
	volume    = {abs/1706.03825},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03825},
	eprinttype = {arXiv},
	eprint    = {1706.03825},
	timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SmilkovTKVW17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 25. Var Grad Method refernece 
@article{DBLP:journals/corr/abs-1810-03307,
	author    = {Julius Adebayo and
	Justin Gilmer and
	Ian J. Goodfellow and
	Been Kim},
	title     = {Local Explanation Methods for Deep Neural Networks Lack Sensitivity
	to Parameter Values},
	journal   = {CoRR},
	volume    = {abs/1810.03307},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.03307},
	eprinttype = {arXiv},
	eprint    = {1810.03307},
	timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1810-03307.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 26. Shapely Value Sampling 1
@article{CASTRO20091726,
	title = {Polynomial calculation of the Shapley value based on sampling},
	journal = {Computers and Operations Research},
	volume = {36},
	number = {5},
	pages = {1726-1730},
	year = {2009},
	note = {Selected papers presented at the Tenth International Symposium on Locational Decisions (ISOLDE X)},
	issn = {0305-0548},
	doi = {https://doi.org/10.1016/j.cor.2008.04.004},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054808000804},
	author = {Javier Castro and Daniel Gómez and Juan Tejada},
	keywords = {Game theory, Shapley value, Sampling algorithm},
	abstract = {In this paper we develop a polynomial method based on sampling theory that can be used to estimate the Shapley value (or any semivalue) for cooperative games. Besides analyzing the complexity problem, we examine some desirable statistical properties of the proposed approach and provide some computational results.}
}

% 27. Shapely Value Sampling 2
@article{trumbelj2010AnEE,
	title={An Efficient Explanation of Individual Classifications using Game Theory},
	author={Erik Strumbelj and Igor Kononenko},
	journal={J. Mach. Learn. Res.},
	year={2010},
	volume={11},
	pages={1-18}
}

% 28. Shapely Value Sampling 3
@inbook{Shapley+2016+307+318,
	url = {https://doi.org/10.1515/9781400881970-018},
	title = {17. A Value for n-Person Games},
	booktitle = {Contributions to the Theory of Games (AM-28), Volume II},
	author = {L. S. Shapley},
	editor = {Harold William Kuhn and Albert William Tucker},
	publisher = {Princeton University Press},
	address = {Princeton},
	pages = {307--318},
	doi = {doi:10.1515/9781400881970-018},
	isbn = {9781400881970},
	year = {2016},
	lastchecked = {2022-10-13}
}
% 29. Survey
@Article{electronics10050593,
	AUTHOR = {Zhou, Jianlong and Gandomi, Amir H. and Chen, Fang and Holzinger, Andreas},
	TITLE = {Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics},
	JOURNAL = {Electronics},
	VOLUME = {10},
	YEAR = {2021},
	NUMBER = {5},
	ARTICLE-NUMBER = {593},
	URL = {https://www.mdpi.com/2079-9292/10/5/593},
	ISSN = {2079-9292},
	ABSTRACT = {The most successful Machine Learning (ML) systems remain complex black boxes to end-users, and even experts are often unable to understand the rationale behind their decisions. The lack of transparency of such systems can have severe consequences or poor uses of limited valuable resources in medical diagnosis, financial decision-making, and in other high-stake domains. Therefore, the issue of ML explanation has experienced a surge in interest from the research community to application domains. While numerous explanation methods have been explored, there is a need for evaluations to quantify the quality of explanation methods to determine whether and to what extent the offered explainability achieves the defined objective, and compare available explanation methods and suggest the best explanation from the comparison for a specific task. This survey paper presents a comprehensive overview of methods proposed in the current literature for the evaluation of ML explanations. We identify properties of explainability from the review of definitions of explainability. The identified properties of explainability are used as objectives that evaluation metrics should achieve. The survey found that the quantitative metrics for both model-based and example-based explanations are primarily used to evaluate the parsimony/simplicity of interpretability, while the quantitative metrics for attribution-based explanations are primarily used to evaluate the soundness of fidelity of explainability. The survey also demonstrated that subjective measures, such as trust and confidence, have been embraced as the focal point for the human-centered evaluation of explainable systems. The paper concludes that the evaluation of ML explanations is a multidisciplinary research topic. It is also not possible to define an implementation of evaluation metrics, which can be applied to all explanation methods.},
	DOI = {10.3390/electronics10050593}
}

% 30. Axiomatic approach 

@article{DBLP:journals/corr/abs-2007-07584,
	author    = {An-phi Nguyen and María Rodríguez Martínez},
	title     = {On quantitative aspects of model interpretability},
	journal   = {CoRR},
	volume    = {abs/2007.07584},
	year      = {2020},
	url       = {https://arxiv.org/abs/2007.07584},
	eprinttype = {arXiv},
	eprint    = {2007.07584},
	timestamp = {Sun, 02 Oct 2022 15:32:02 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2007-07584.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 31. SSIM refrence
@article{1284395,
	author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	journal={IEEE Transactions on Image Processing}, 
	title={Image quality assessment: from error visibility to structural similarity}, 
	year={2004},
	volume={13},
	number={4},
	pages={600-612},
	doi={10.1109/TIP.2003.819861}
}

% 32. Continunity 
@misc{https://doi.org/10.48550/arxiv.1711.00867,
	doi = {10.48550/ARXIV.1711.00867},
	url = {https://arxiv.org/abs/1711.00867},
	author = {Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Schütt, Kristof T. and Dähne, Sven and Erhan, Dumitru and Kim, Been},
	keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {The (Un)reliability of saliency methods},
	publisher = {arXiv},
	year = {2017},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 33. Shapley values
@misc{https://doi.org/10.48550/arxiv.2104.12199,
	doi = {10.48550/ARXIV.2104.12199},
	url = {https://arxiv.org/abs/2104.12199},
	author = {Mitchell, Rory and Cooper, Joshua and Frank, Eibe and Holmes, Geoffrey},
	keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Combinatorics (math.CO), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics, I.2.6; G.2.1, 05A05 (Primary) 65K10, 90C27 (Secondary)},
	title = {Sampling Permutations for Shapley Value Estimation},
	publisher = {arXiv},
	year = {2021},
	copyright = {Creative Commons Attribution 4.0 International}
}

% 34. Shapley values
@misc{https://doi.org/10.48550/arxiv.1903.10464,
	doi = {10.48550/ARXIV.1903.10464},
	url = {https://arxiv.org/abs/1903.10464},
	author = {Aas, Kjersti and Jullum, Martin and Løland, Anders},
	keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Explaining individual predictions when features are dependent: More accurate approximations to Shapley values},
	publisher = {arXiv},
	year = {2019},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% 35. ERASER
@article{DBLP:journals/corr/abs-1911-03429,
	author    = {Jay DeYoung and
	Sarthak Jain and
	Nazneen Fatema Rajani and
	Eric Lehman and
	Caiming Xiong and
	Richard Socher and
	Byron C. Wallace},
	title     = {{ERASER:} {A} Benchmark to Evaluate Rationalized {NLP} Models},
	journal   = {CoRR},
	volume    = {abs/1911.03429},
	year      = {2019},
	url       = {http://arxiv.org/abs/1911.03429},
	eprinttype = {arXiv},
	eprint    = {1911.03429},
	timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1911-03429.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 36. BERT
@inproceedings{devlin-etal-2019-bert,
	title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
	author = "Devlin, Jacob  and
	Chang, Ming-Wei  and
	Lee, Kenton  and
	Toutanova, Kristina",
	booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/N19-1423",
	doi = "10.18653/v1/N19-1423",
	pages = "4171--4186",
	abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}
% 37. Trees explanations evaluations 
@article{DBLP:journals/corr/abs-1905-04610,
	author    = {Scott M. Lundberg and
	Gabriel G. Erion and
	Hugh Chen and
	Alex J. DeGrave and
	Jordan M. Prutkin and
	Bala Nair and
	Ronit Katz and
	Jonathan Himmelfarb and
	Nisha Bansal and
	Su{-}In Lee},
	title     = {Explainable {AI} for Trees: From Local Explanations to Global Understanding},
	journal   = {CoRR},
	volume    = {abs/1905.04610},
	year      = {2019},
	url       = {http://arxiv.org/abs/1905.04610},
	eprinttype = {arXiv},
	eprint    = {1905.04610},
	timestamp = {Fri, 26 Nov 2021 16:33:35 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-04610.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 38. Human study framework
@article{DBLP:journals/corr/abs-2005-01831,
	author    = {Peter Hase and
	Mohit Bansal},
	title     = {Evaluating Explainable {AI:} Which Algorithmic Explanations Help Users
	Predict Model Behavior?},
	journal   = {CoRR},
	volume    = {abs/2005.01831},
	year      = {2020},
	url       = {https://arxiv.org/abs/2005.01831},
	eprinttype = {arXiv},
	eprint    = {2005.01831},
	timestamp = {Fri, 08 May 2020 15:04:04 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2005-01831.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 39. AUC NLP and vision 
@article{DBLP:journals/corr/abs-2012-09838,
	author    = {Hila Chefer and
	Shir Gur and
	Lior Wolf},
	title     = {Transformer Interpretability Beyond Attention Visualization},
	journal   = {CoRR},
	volume    = {abs/2012.09838},
	year      = {2020},
	url       = {https://arxiv.org/abs/2012.09838},
	eprinttype = {arXiv},
	eprint    = {2012.09838},
	timestamp = {Sun, 03 Jan 2021 18:46:06 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-09838.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 40 efficient SHAP
@article{strumbelj2010efficient,
	title={An efficient explanation of individual classifications using game theory},
	author={Strumbelj, Erik and Kononenko, Igor},
	journal={The Journal of Machine Learning Research},
	volume={11},
	pages={1--18},
	year={2010},
	publisher={JMLR. org}
}

% 41 . survey
@article{DBLP:journals/corr/abs-2012-14261,
	author    = {Yu Zhang and
	Peter Tino and
	Ales Leonardis and
	Ke Tang},
	title     = {A Survey on Neural Network Interpretability},
	journal   = {CoRR},
	volume    = {abs/2012.14261},
	year      = {2020},
	url       = {https://arxiv.org/abs/2012.14261},
	eprinttype = {arXiv},
	eprint    = {2012.14261},
	timestamp = {Fri, 19 Nov 2021 11:17:18 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-14261.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 42 . review - DBLP:journals/corr/abs-2007-15911
@article{DBLP:journals/corr/abs-2007-15911,
	author    = {Aniek F. Markus and
	Jan A. Kors and
	Peter R. Rijnbeek},
	title     = {The role of explainability in creating trustworthy artificial intelligence
	for health care: a comprehensive survey of the terminology, design
	choices, and evaluation strategies},
	journal   = {CoRR},
	volume    = {abs/2007.15911},
	year      = {2020},
	url       = {https://arxiv.org/abs/2007.15911},
	eprinttype = {arXiv},
	eprint    = {2007.15911},
	timestamp = {Mon, 03 Aug 2020 14:32:13 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2007-15911.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 43 . HUman study subjects
@article{DBLP:journals/corr/RibeiroSG16,
	author    = {Marco Tulio Ribeiro and
	Sameer Singh and
	Carlos Guestrin},
	title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
	journal   = {CoRR},
	volume    = {abs/1602.04938},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.04938},
	eprinttype = {arXiv},
	eprint    = {1602.04938},
	timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/RibeiroSG16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 44. A whole book about interpetabily 
@book{samek2019explainable,
	title={Explainable AI: interpreting, explaining and visualizing deep learning},
	author={Samek, Wojciech and Montavon, Grégoire and Vedaldi, Andrea and Hansen, Lars Kai and Müller, Klaus-Robert},
	volume={11700},
	year={2019},
	publisher={Springer Nature}
}

% 45
@article{DBLP:journals/corr/abs-1904-11829,
	author    = {Leila Arras and
	Ahmed Osman and
	Klaus-Robert Müller and
	Wojciech Samek},
	title     = {Evaluating Recurrent Neural Network Explanations},
	journal   = {CoRR},
	volume    = {abs/1904.11829},
	year      = {2019},
	url       = {http://arxiv.org/abs/1904.11829},
	eprinttype = {arXiv},
	eprint    = {1904.11829},
	timestamp = {Thu, 02 May 2019 15:13:44 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1904-11829.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 46 - Survey

@article{DBLP:journals/corr/abs-2012-15445,
	author    = {Hao Yuan and
	Haiyang Yu and
	Shurui Gui and
	Shuiwang Ji},
	title     = {Explainability in Graph Neural Networks: {A} Taxonomic Survey},
	journal   = {CoRR},
	volume    = {abs/2012.15445},
	year      = {2020},
	url       = {https://arxiv.org/abs/2012.15445},
	eprinttype = {arXiv},
	eprint    = {2012.15445},
	timestamp = {Fri, 08 Jan 2021 17:23:09 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-15445.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


% 47 - AOPC 
@inproceedings{nguyen-2018-comparing,
	title = "Comparing Automatic and Human Evaluation of Local Explanations for Text Classification",
	author = "Nguyen, Dong",
	booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
	month = jun,
	year = "2018",
	address = "New Orleans, Louisiana",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/N18-1097",
	doi = "10.18653/v1/N18-1097",
	pages = "1069--1078",
	abstract = "Text classification models are becoming increasingly complex and opaque, however for many applications it is essential that the models are interpretable. Recently, a variety of approaches have been proposed for generating local explanations. While robust evaluations are needed to drive further progress, so far it is unclear which evaluation approaches are suitable. This paper is a first step towards more robust evaluations of local explanations. We evaluate a variety of local explanation approaches using automatic measures based on word deletion. Furthermore, we show that an evaluation using a crowdsourcing experiment correlates moderately with these automatic measures and that a variety of other factors also impact the human judgements.",
}

% 48. Integrated Hesians 

@article{DBLP:journals/corr/abs-2002-04138,
	author    = {Joseph D. Janizek and
	Pascal Sturmfels and
	Su{-}In Lee},
	title     = {Explaining Explanations: Axiomatic Feature Interactions for Deep Networks},
	journal   = {CoRR},
	volume    = {abs/2002.04138},
	year      = {2020},
	url       = {https://arxiv.org/abs/2002.04138},
	eprinttype = {arXiv},
	eprint    = {2002.04138},
	timestamp = {Wed, 12 Feb 2020 16:38:55 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2002-04138.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 49 . Fooling explanations 
@article{DBLP:journals/corr/abs-1902-02041,
	author    = {Juyeon Heo and
	Sunghwan Joo and
	Taesup Moon},
	title     = {Fooling Neural Network Interpretations via Adversarial Model Manipulation},
	journal   = {CoRR},
	volume    = {abs/1902.02041},
	year      = {2019},
	url       = {http://arxiv.org/abs/1902.02041},
	eprinttype = {arXiv},
	eprint    = {1902.02041},
	timestamp = {Tue, 21 May 2019 18:03:38 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1902-02041.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 50
@article{DBLP:journals/corr/abs-2005-00631,
	author    = {Umang Bhatt and
	Adrian Weller and
	Jose M. F. Mour},
	title     = {Evaluating and Aggregating Feature-based Model Explanations},
	journal   = {CoRR},
	volume    = {abs/2005.00631},
	year      = {2020},
	url       = {https://arxiv.org/abs/2005.00631},
	eprinttype = {arXiv},
	eprint    = {2005.00631},
	timestamp = {Fri, 08 May 2020 15:04:04 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2005-00631.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 51
@article{DBLP:journals/corr/abs-1912-01451,
	author    = {Richard Tomsett and
	Dan Harborne and
	Supriyo Chakraborty and
	Prudhvi Gurram and
	Alun D. Preece},
	title     = {Sanity Checks for Saliency Metrics},
	journal   = {CoRR},
	volume    = {abs/1912.01451},
	year      = {2019},
	url       = {http://arxiv.org/abs/1912.01451},
	eprinttype = {arXiv},
	eprint    = {1912.01451},
	timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01451.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 52 Gradient times input
@article{DBLP:journals/corr/ShrikumarGSK16,
	author    = {Avanti Shrikumar and
	Peyton Greenside and
	Anna Shcherbina and
	Anshul Kundaje},
	title     = {Not Just a Black Box: Learning Important Features Through Propagating
	Activation Differences},
	journal   = {CoRR},
	volume    = {abs/1605.01713},
	year      = {2016},
	url       = {http://arxiv.org/abs/1605.01713},
	eprinttype = {arXiv},
	eprint    = {1605.01713},
	timestamp = {Mon, 13 Aug 2018 16:48:14 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ShrikumarGSK16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 52 Guided Grad CAM

@article{DBLP:journals/corr/SelvarajuDVCPB16,
	author    = {Ramprasaath R. Selvaraju and
	Abhishek Das and
	Ramakrishna Vedantam and
	Michael Cogswell and
	Devi Parikh and
	Dhruv Batra},
	title     = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
	via Gradient-based Localization},
	journal   = {CoRR},
	volume    = {abs/1610.02391},
	year      = {2016},
	url       = {http://arxiv.org/abs/1610.02391},
	eprinttype = {arXiv},
	eprint    = {1610.02391},
	timestamp = {Mon, 13 Aug 2018 16:46:58 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

# 53 Deconve
@InProceedings{10.1007/978-3-319-46466-4_8,
	author="Mahendran, Aravindh
	and Vedaldi, Andrea",
	editor="Leibe, Bastian
	and Matas, Jiri
	and Sebe, Nicu
	and Welling, Max",
	title="Salient Deconvolutional Networks",
	booktitle="Computer Vision -- ECCV 2016",
	year="2016",
	publisher="Springer International Publishing",
	address="Cham",
	pages="120--135",
	abstract="Deconvolution is a popular method for visualizing deep convolutional neural networks; however, due to their heuristic nature, the meaning of deconvolutional visualizations is not entirely clear. In this paper, we introduce a family of reversed networks that generalizes and relates deconvolution, backpropagation and network saliency. We use this construction to thoroughly investigate and compare these methods in terms of quality and meaning of the produced images, and of what architectural choices are important in determining these properties. We also show an application of these generalized deconvolutional networks to weakly-supervised foreground object segmentation.",
	isbn="978-3-319-46466-4"
}

# 54 Deconve
@article{DBLP:journals/corr/ZeilerF13,
	author    = {Matthew D. Zeiler and
	Rob Fergus},
	title     = {Visualizing and Understanding Convolutional Networks},
	journal   = {CoRR},
	volume    = {abs/1311.2901},
	year      = {2013},
	url       = {http://arxiv.org/abs/1311.2901},
	eprinttype = {arXiv},
	eprint    = {1311.2901},
	timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ZeilerF13.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


# 55 CAM
@article{DBLP:journals/corr/ZhouKLOT15,
	author    = {Bolei Zhou and
	Aditya Khosla and
	{\`{A}}gata Lapedriza and
	Aude Oliva and
	Antonio Torralba},
	title     = {Learning Deep Features for Discriminative Localization},
	journal   = {CoRR},
	volume    = {abs/1512.04150},
	year      = {2015},
	url       = {http://arxiv.org/abs/1512.04150},
	eprinttype = {arXiv},
	eprint    = {1512.04150},
	timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ZhouKLOT15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


# 56 Guided back propogation
@misc{https://doi.org/10.48550/arxiv.1412.6806,
	doi = {10.48550/ARXIV.1412.6806},
	url = {https://arxiv.org/abs/1412.6806},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Striving for Simplicity: The All Convolutional Net},
	publisher = {arXiv},
	year = {2014},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

# 57 Adversarial 1
@article{DBLP:journals/corr/abs-1902-02041,
	author    = {Juyeon Heo and
	Sunghwan Joo and
	Taesup Moon},
	title     = {Fooling Neural Network Interpretations via Adversarial Model Manipulation},
	journal   = {CoRR},
	volume    = {abs/1902.02041},
	year      = {2019},
	url       = {http://arxiv.org/abs/1902.02041},
	eprinttype = {arXiv},
	eprint    = {1902.02041},
	timestamp = {Tue, 21 May 2019 18:03:38 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1902-02041.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

# 58 Adversarial 2
@article{DBLP:journals/corr/abs-1911-02508,
	author    = {Dylan Slack and
	Sophie Hilgard and
	Emily Jia and
	Sameer Singh and
	Himabindu Lakkaraju},
	title     = {How can we fool {LIME} and SHAP? Adversarial Attacks on Post hoc Explanation
	Methods},
	journal   = {CoRR},
	volume    = {abs/1911.02508},
	year      = {2019},
	url       = {http://arxiv.org/abs/1911.02508},
	eprinttype = {arXiv},
	eprint    = {1911.02508},
	timestamp = {Mon, 24 Feb 2020 12:40:23 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1911-02508.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


# 59 Adversarial 3
@misc{https://doi.org/10.48550/arxiv.1906.07983,
	doi = {10.48550/ARXIV.1906.07983},	
	url = {https://arxiv.org/abs/1906.07983},
	author = {Dombrowski, Ann-Kathrin and Alber, Maximilian and Anders, Christopher J. and Ackermann, Marcel and Müller, Klaus-Robert and Kessel, Pan},
	keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Explanations can be manipulated and geometry is to blame},
	publisher = {arXiv},
	year = {2019},
	copyright = {arXiv.org perpetual, non-exclusive license}
}
