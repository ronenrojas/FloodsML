@article{Mcgovern,
	author = {Mcgovern, Amy and Lagerquist, Ryan and Gagne, David and Jergensen, G. and Elmore, Kimberly and Homeyer, Cameron and Smith, Travis},
	year = {2019},
	month = {08},
	pages = {},
	title = {Making the Black Box More Transparent: Understanding the Physical Implications of Machine Learning},
	volume = {100},
	journal = {Bulletin of the American Meteorological Society},
	doi = {10.1175/BAMS-D-18-0195.1}
}

% Extensive book about interpatibitly 
@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

% Cite for deep learining in general for the intro
@misc{he2015deep,
	author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title={Deep Residual Learning for Image Recognition}, 
	year={2015},
	eprint={1512.03385},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

% Cite for deep learining in general for the intro
@article{DBLP:journals/corr/abs-1805-01890,
	author    = {Kamran Kowsari and
	Mojtaba Heidarysafa and
	Donald E. Brown and
	Kiana Jafari Meimandi and
	Laura E. Barnes},
	title     = {{RMDL:} Random Multimodel Deep Learning for Classification},
	journal   = {CoRR},
	volume    = {abs/1805.01890},
	year      = {2018},
	url       = {http://arxiv.org/abs/1805.01890},
	eprinttype = {arXiv},
	eprint    = {1805.01890},
	timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1805-01890.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Cite for deep learining in general for the intro
@article{DBLP:journals/corr/abs-1905-01392,
	author    = {Martin Wistuba and
	Ambrish Rawat and
	Tejaswini Pedapati},
	title     = {A Survey on Neural Architecture Search},
	journal   = {CoRR},
	volume    = {abs/1905.01392},
	year      = {2019},
	url       = {http://arxiv.org/abs/1905.01392},
	eprinttype = {arXiv},
	eprint    = {1905.01392},
	timestamp = {Mon, 27 May 2019 13:15:00 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-01392.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Cite for deep learining in general for the intro
@article{DBLP:journals/corr/MnihKSGAWR13,
	author    = {Volodymyr Mnih and
	Koray Kavukcuoglu and
	David Silver and
	Alex Graves and
	Ioannis Antonoglou and
	Daan Wierstra and
	Martin A. Riedmiller},
	title     = {Playing Atari with Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1312.5602},
	year      = {2013},
	url       = {http://arxiv.org/abs/1312.5602},
	eprinttype = {arXiv},
	eprint    = {1312.5602},
	timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Cite for deep learining in general for the intro
@article{Silver_2016,
	added-at = {2016-03-11T14:36:05.000+0100},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
	doi = {10.1038/nature16961},
	interhash = {48430c7891aaf9fe2582faa8f5d076c1},
	intrahash = {9e987f58d895c490144693139cbc90c7},
	journal = {Nature},
	keywords = {baduk go google},
	month = jan,
	number = 7587,
	pages = {484--489},
	publisher = {Nature Publishing Group},
	timestamp = {2016-03-11T14:37:40.000+0100},
	title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
	volume = 529,
	year = 2016
}

% Integrated Gradient paper
@article{DBLP:journals/corr/SundararajanTY17,
	author    = {Mukund Sundararajan and
	Ankur Taly and
	Qiqi Yan},
	title     = {Axiomatic Attribution for Deep Networks},
	journal   = {CoRR},
	volume    = {abs/1703.01365},
	year      = {2017},
	url       = {http://arxiv.org/abs/1703.01365},
	eprinttype = {arXiv},
	eprint    = {1703.01365},
	timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SundararajanTY17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Local attributions Vs. Global and Sensitivity-n metric
@misc{https://doi.org/10.48550/arxiv.1711.06104,
	doi = {10.48550/ARXIV.1711.06104},
	url = {https://arxiv.org/abs/1711.06104},
	author = {Ancona, Marco and Ceolini, Enea and Öztireli, Cengiz and Gross, Markus},
	keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Towards better understanding of gradient-based attribution methods for Deep Neural Networks},
	publisher = {arXiv},
	year = {2017},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% Deep Lift Shap
@article{DBLP:journals/corr/LundbergL17,
	author    = {Scott M. Lundberg and
	Su{-}In Lee},
	title     = {A unified approach to interpreting model predictions},
	journal   = {CoRR},
	volume    = {abs/1705.07874},
	year      = {2017},
	url       = {http://arxiv.org/abs/1705.07874},
	eprinttype = {arXiv},
	eprint    = {1705.07874},
	timestamp = {Fri, 26 Nov 2021 16:33:36 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/LundbergL17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/ShrikumarGK17,
	author    = {Avanti Shrikumar and
	Peyton Greenside and
	Anshul Kundaje},
	title     = {Learning Important Features Through Propagating Activation Differences},
	journal   = {CoRR},
	volume    = {abs/1704.02685},
	year      = {2017},
	url       = {http://arxiv.org/abs/1704.02685},
	eprinttype = {arXiv},
	eprint    = {1704.02685},
	timestamp = {Thu, 14 Oct 2021 09:14:21 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ShrikumarGK17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2111-07668,
	author    = {Robin Hesse and
	Simone Schaub{-}Meyer and
	Stefan Roth},
	title     = {Fast Axiomatic Attribution for Neural Networks},
	journal   = {CoRR},
	volume    = {abs/2111.07668},
	year      = {2021},
	url       = {https://arxiv.org/abs/2111.07668},
	eprinttype = {arXiv},
	eprint    = {2111.07668},
	timestamp = {Tue, 16 Nov 2021 12:12:31 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2111-07668.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1802-00614,
	author    = {Quanshi Zhang and
	Song{-}Chun Zhu},
	title     = {Visual Interpretability for Deep Learning: a Survey},
	journal   = {CoRR},
	volume    = {abs/1802.00614},
	year      = {2018},
	url       = {http://arxiv.org/abs/1802.00614},
	eprinttype = {arXiv},
	eprint    = {1802.00614},
	timestamp = {Mon, 13 Aug 2018 16:46:30 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1802-00614.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
 
% Benchmark
@misc{https://doi.org/10.48550/arxiv.1806.10758,
	doi = {10.48550/ARXIV.1806.10758},
	url = {https://arxiv.org/abs/1806.10758},
	author = {Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
	keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {A Benchmark for Interpretability Methods in Deep Neural Networks},
	publisher = {arXiv},
	year = {2018},
	copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.1509.06321,
	doi = {10.48550/ARXIV.1509.06321},
	url = {https://arxiv.org/abs/1509.06321},
	author = {Samek, Wojciech and Binder, Alexander and Montavon, Grégoire and Bach, Sebastian and Müller, Klaus-Robert},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Evaluating the visualization of what a Deep Neural Network has learned},
	publisher = {arXiv},
	year = {2015},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% referenceExplanation Selectivity
@article{DBLP:journals/corr/MontavonSM17,
	author    = {Grégoire Montavon and
	Wojciech Samek and
	Klaus-Robert Müller},
	title     = {Methods for Interpreting and Understanding Deep Neural Networks},
	journal   = {CoRR},
	volume    = {abs/1706.07979},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.07979},
	eprinttype = {arXiv},
	eprint    = {1706.07979},
	timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/MontavonSM17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
% LRP Method 

@article{LRP,
	author = {Lapuschkin, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2015},
	month = {07},
	pages = {e0130140},
	title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
	volume = {10},
	journal = {PLoS ONE},
	doi = {10.1371/journal.pone.0130140}
}

% LRP word emmbeding zero
@article{DBLP:journals/corr/ArrasHMMS16a,
	author    = {Leila Arras and
	Franziska Horn and
	Grégoire  Montavon and
	Klaus-Robert Müller and
	Wojciech Samek},
	title     = {"What is Relevant in a Text Document?": An Interpretable Machine Learning
	Approach},
	journal   = {CoRR},
	volume    = {abs/1612.07843},
	year      = {2016},
	url       = {http://arxiv.org/abs/1612.07843},
	eprinttype = {arXiv},
	eprint    = {1612.07843},
	timestamp = {Mon, 13 Aug 2018 16:47:50 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ArrasHMMS16a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
% Debugging reference 1
@misc{https://doi.org/10.48550/arxiv.1810.03292,
	doi = {10.48550/ARXIV.1810.03292},
	url = {https://arxiv.org/abs/1810.03292},
	author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Sanity Checks for Saliency Maps},
	publisher = {arXiv},
	year = {2018},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% Debugging reference 2

@article{DBLP:journals/corr/abs-2011-05429,
	author    = {Julius Adebayo and
	Michael Muelly and
	Ilaria Liccardi and
	Been Kim},
	title     = {Debugging Tests for Model Explanations},
	journal   = {CoRR},
	volume    = {abs/2011.05429},
	year      = {2020},
	url       = {https://arxiv.org/abs/2011.05429},
	eprinttype = {arXiv},
	eprint    = {2011.05429},
	timestamp = {Thu, 12 Nov 2020 15:14:56 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2011-05429.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Gradient Method refernece 
@article{baehrens2010explain,
	title={How to explain individual classification decisions},
	author={Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\"u}ller, Klaus-Robert},
	journal={The Journal of Machine Learning Research},
	volume={11},
	pages={1803--1831},
	year={2010},
	publisher={JMLR. org}
}

% Gradient Method refernece 
@misc{https://doi.org/10.48550/arxiv.1312.6034,
	doi = {10.48550/ARXIV.1312.6034},
	url = {https://arxiv.org/abs/1312.6034},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	publisher = {arXiv},
	year = {2013},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

% Smooth Gradient Method refernece 
@article{DBLP:journals/corr/SmilkovTKVW17,
	author    = {Daniel Smilkov and
	Nikhil Thorat and
	Been Kim and
	Fernanda B. Vi{\'{e}}gas and
	Martin Wattenberg},
	title     = {SmoothGrad: removing noise by adding noise},
	journal   = {CoRR},
	volume    = {abs/1706.03825},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03825},
	eprinttype = {arXiv},
	eprint    = {1706.03825},
	timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/SmilkovTKVW17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Var Grad Method refernece 
@article{DBLP:journals/corr/abs-1810-03307,
	author    = {Julius Adebayo and
	Justin Gilmer and
	Ian J. Goodfellow and
	Been Kim},
	title     = {Local Explanation Methods for Deep Neural Networks Lack Sensitivity
	to Parameter Values},
	journal   = {CoRR},
	volume    = {abs/1810.03307},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.03307},
	eprinttype = {arXiv},
	eprint    = {1810.03307},
	timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1810-03307.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Shapely Value Sampling 1
@article{CASTRO20091726,
	title = {Polynomial calculation of the Shapley value based on sampling},
	journal = {Computers and Operations Research},
	volume = {36},
	number = {5},
	pages = {1726-1730},
	year = {2009},
	note = {Selected papers presented at the Tenth International Symposium on Locational Decisions (ISOLDE X)},
	issn = {0305-0548},
	doi = {https://doi.org/10.1016/j.cor.2008.04.004},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054808000804},
	author = {Javier Castro and Daniel Gómez and Juan Tejada},
	keywords = {Game theory, Shapley value, Sampling algorithm},
	abstract = {In this paper we develop a polynomial method based on sampling theory that can be used to estimate the Shapley value (or any semivalue) for cooperative games. Besides analyzing the complexity problem, we examine some desirable statistical properties of the proposed approach and provide some computational results.}
}

% Shapely Value Sampling 2
@article{trumbelj2010AnEE,
	title={An Efficient Explanation of Individual Classifications using Game Theory},
	author={Erik Strumbelj and Igor Kononenko},
	journal={J. Mach. Learn. Res.},
	year={2010},
	volume={11},
	pages={1-18}
}

% Shapely Value Sampling 3
@inbook{Shapley+2016+307+318,
	url = {https://doi.org/10.1515/9781400881970-018},
	title = {17. A Value for n-Person Games},
	booktitle = {Contributions to the Theory of Games (AM-28), Volume II},
	author = {L. S. Shapley},
	editor = {Harold William Kuhn and Albert William Tucker},
	publisher = {Princeton University Press},
	address = {Princeton},
	pages = {307--318},
	doi = {doi:10.1515/9781400881970-018},
	isbn = {9781400881970},
	year = {2016},
	lastchecked = {2022-10-13}
}
% Survey
@Article{electronics10050593,
	AUTHOR = {Zhou, Jianlong and Gandomi, Amir H. and Chen, Fang and Holzinger, Andreas},
	TITLE = {Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics},
	JOURNAL = {Electronics},
	VOLUME = {10},
	YEAR = {2021},
	NUMBER = {5},
	ARTICLE-NUMBER = {593},
	URL = {https://www.mdpi.com/2079-9292/10/5/593},
	ISSN = {2079-9292},
	ABSTRACT = {The most successful Machine Learning (ML) systems remain complex black boxes to end-users, and even experts are often unable to understand the rationale behind their decisions. The lack of transparency of such systems can have severe consequences or poor uses of limited valuable resources in medical diagnosis, financial decision-making, and in other high-stake domains. Therefore, the issue of ML explanation has experienced a surge in interest from the research community to application domains. While numerous explanation methods have been explored, there is a need for evaluations to quantify the quality of explanation methods to determine whether and to what extent the offered explainability achieves the defined objective, and compare available explanation methods and suggest the best explanation from the comparison for a specific task. This survey paper presents a comprehensive overview of methods proposed in the current literature for the evaluation of ML explanations. We identify properties of explainability from the review of definitions of explainability. The identified properties of explainability are used as objectives that evaluation metrics should achieve. The survey found that the quantitative metrics for both model-based and example-based explanations are primarily used to evaluate the parsimony/simplicity of interpretability, while the quantitative metrics for attribution-based explanations are primarily used to evaluate the soundness of fidelity of explainability. The survey also demonstrated that subjective measures, such as trust and confidence, have been embraced as the focal point for the human-centered evaluation of explainable systems. The paper concludes that the evaluation of ML explanations is a multidisciplinary research topic. It is also not possible to define an implementation of evaluation metrics, which can be applied to all explanation methods.},
	DOI = {10.3390/electronics10050593}
}

% Axiomatic approach 

@article{DBLP:journals/corr/abs-2007-07584,
	author    = {An-phi Nguyen and María Rodríguez Martínez},
	title     = {On quantitative aspects of model interpretability},
	journal   = {CoRR},
	volume    = {abs/2007.07584},
	year      = {2020},
	url       = {https://arxiv.org/abs/2007.07584},
	eprinttype = {arXiv},
	eprint    = {2007.07584},
	timestamp = {Sun, 02 Oct 2022 15:32:02 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2007-07584.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

% SSIM refrence
@article{1284395,
	author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	journal={IEEE Transactions on Image Processing}, 
	title={Image quality assessment: from error visibility to structural similarity}, 
	year={2004},
	volume={13},
	number={4},
	pages={600-612},
	doi={10.1109/TIP.2003.819861}
}

% Continunity 
@misc{https://doi.org/10.48550/arxiv.1711.00867,
	doi = {10.48550/ARXIV.1711.00867},
	url = {https://arxiv.org/abs/1711.00867},
	author = {Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Schütt, Kristof T. and Dähne, Sven and Erhan, Dumitru and Kim, Been},
	keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {The (Un)reliability of saliency methods},
	publisher = {arXiv},
	year = {2017},
	copyright = {arXiv.org perpetual, non-exclusive license}
}